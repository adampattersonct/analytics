---
title: "Excel Literacy Results"
author: "Oskar Harmon, PhD"
date: "12/4/2022"
output: pdf_document
---

```{r setup, include=FALSE}
#export_summs(ols1, ols2, scale = TRUE)
library(reshape2) 
library(gridExtra)  
library(sjPlot)
library(sjmisc)
library(sjlabelled)
library(formattable)
library(openxlsx)
library(dplyr)
library(plyr)
library(mfx)
library(leaps)
library(car)
library(ggplot2)
library(ridgeline)
library(plyr)
library(fastDummies)
library(stargazer)
library(jtools)
setwd("~/Desktop/Data Literacy/R")
m<-read.csv("cleanedPrePostSurvey112222.csv")
m$question_percentLog<-log(m$question_percent+1)
m$Gender<-revalue(m$Sex,c("Male"=1,"Female"=0))
m$Female<-revalue(m$Sex,c("Male"=0,"Female"=1))
m$Ethnicity<-revalue(m$Ethnicity_NRA_included,c('Asian'="Asian","Black/African American"="Black","Hispanic/Latino"="Hispanic","NRA"="NRA","Two or more races"="Multiracial","White"="White"))
m <- dummy_cols(m, select_columns = 'Ethnicity')
m$Confidence<-round(m$ConfidenceAvg)
means<-m[,c(56,102,57,99,103:104,106:111)]
colnames(means)[1]<-"Percent Correct"
colnames(means)[2]<-"Percent Correct Log"
colnames(means)[3]<-"Average Confidence"
colnames(means)[4]<-"Cumulative GPA"
colnames(means)[5]<-"Male"
colnames(means)[6]<-"Female"
colnames(means)[7]<-"Asian"
colnames(means)[8]<-"Black"
colnames(means)[9]<-"Hispanic"
colnames(means)[10]<-"Multiracial"
colnames(means)[11]<-"Non-Resident Alien"
colnames(means)[12]<-"White"
means$Male<-as.numeric(means$Male)
means$Female<-as.numeric(means$Female)

m3<-m[m$Gender==1,]
m4<-m[m$Gender==0,]

level_order<-c("Sum","Median","Avg","VLOOKUP","Sort","IF THEN","Intercept")


# Confidence Interval Cleaning 
sum_one<-sum(m$q1dummy)/nrow(m)
sum_two<-sum(m$q2dummy)/nrow(m)
sum_three<-sum(m$q3dummy)/nrow(m)
sum_four<-sum(m$q4dummy)/nrow(m)
sum_six<-sum(m$q6dummy)/nrow(m)
sum_seven<-sum(m$q7dummy)/nrow(m)
sum_eight<-sum(m$q8dummy)/nrow(m)

conf_one<-mean(as.numeric(m$Q6.x), na.rm = TRUE)/7
conf_two<-mean(as.numeric(m$Q8.x), na.rm = TRUE)/7
conf_three<-mean(as.numeric(m$Q10), na.rm = TRUE)/7
conf_four<-mean(as.numeric(m$Q16), na.rm = TRUE)/7
conf_six<-mean(as.numeric(m$Q17), na.rm = TRUE)/7
conf_seven<-mean(as.numeric(m$Q6.x), na.rm = TRUE)/7
conf_eight<-mean(as.numeric(m$Q8.x), na.rm = TRUE)/7

##### Merge data together
pre_percentages<-c(sum_one,sum_two,sum_three,sum_four,sum_six,sum_seven,sum_eight)
#post_percentages<-c(post1,post2,post3,post4)

pre_confidence<-c(conf_one,conf_two,conf_three,conf_four,conf_six,conf_seven,conf_eight)
#post_confidence<-c(post_con1,post_con2,post_con3,post_con4)

#data3<-as.data.frame(cbind(pre_percentages,post_percentages,pre_confidence,post_confidence))
data3<-as.data.frame(cbind(pre_percentages,pre_confidence))

# Transpose dataset 
data4<-t(data3)
data4<-`colnames<-`(data4, c("Sort","Sum","Avg","Median","IF THEN","Intercept","VLOOKUP"))
data4<-round(data4,2)
data4<-as.data.frame(data4)

x = c("Sort","Sum","Avg","Median","IF THEN","Intercept","VLOOKUP")
data4[1,]
Pre_ = data4[1,]
Post_ = round((data4[2,]),2)
#Post_ = round((data4[2,]/4),2)
library(reshape2)
library(stargazer)
to_plot <- data.frame(x=x,y1=t(Pre_),y2=t(Post_))
melted<-melt(to_plot, id="x")




# Confidence Interval Cleaning for just male
sum_one3<-sum(m3$q1dummy)/nrow(m3)
sum_two3<-sum(m3$q2dummy)/nrow(m3)
sum_three3<-sum(m3$q3dummy)/nrow(m3)
sum_four3<-sum(m3$q4dummy)/nrow(m3)
sum_six3<-sum(m3$q6dummy)/nrow(m3)
sum_seven3<-sum(m3$q7dummy)/nrow(m3)
sum_eight3<-sum(m3$q8dummy)/nrow(m3)

conf_one3<-mean(as.numeric(m3$Q6.x), na.rm = TRUE)/7
conf_two3<-mean(as.numeric(m3$Q8.x), na.rm = TRUE)/7
conf_three3<-mean(as.numeric(m3$Q10), na.rm = TRUE)/7
conf_four3<-mean(as.numeric(m3$Q16), na.rm = TRUE)/7
conf_six3<-mean(as.numeric(m3$Q17), na.rm = TRUE)/7
conf_seven3<-mean(as.numeric(m3$Q6.x), na.rm = TRUE)/7
conf_eight3<-mean(as.numeric(m3$Q8.x), na.rm = TRUE)/7
##### Merge data together
pre_percentages3<-c(sum_one3,sum_two3,sum_three3,sum_four3,sum_six3,sum_seven3,sum_eight3)
#post_percentages<-c(post1,post2,post3,post4)

pre_confidence3<-c(conf_one3,conf_two3,conf_three3,conf_four3,conf_six3,conf_seven3,conf_eight3)
#post_confidence<-c(post_con1,post_con2,post_con3,post_con4)

#data3<-as.data.frame(cbind(pre_percentages,post_percentages,pre_confidence,post_confidence))
data33<-as.data.frame(cbind(pre_percentages3,pre_confidence3))
# Transpose dataset 
data43<-t(data33)
data43<-`colnames<-`(data43, c("Sort","Sum","Avg","Median","IF THEN","Intercept","VLOOKUP"))
data43<-round(data43,2)
data43<-as.data.frame(data43)
x3 = c("Sort","Sum","Avg","Median","IF THEN","Intercept","VLOOKUP")
data43[1,]
Pre_3 = data43[1,]
Post_3 = round((data43[2,]),2)
#Post_ = round((data4[2,]/4),2)
library(reshape2)
library(stargazer)
to_plot3 <- data.frame(x=x3,y1=t(Pre_3),y2=t(Post_3))
melted3<-melt(to_plot3, id="x")

# Confidence Interval Cleaning for Female
sum_one4<-sum(m4$q1dummy)/nrow(m4)
sum_two4<-sum(m4$q2dummy)/nrow(m4)
sum_three4<-sum(m4$q3dummy)/nrow(m4)
sum_four4<-sum(m4$q4dummy)/nrow(m4)
sum_six4<-sum(m4$q6dummy)/nrow(m4)
sum_seven4<-sum(m4$q7dummy)/nrow(m4)
sum_eight4<-sum(m4$q8dummy)/nrow(m4)
conf_one4<-mean(as.numeric(m4$Q6.x), na.rm = TRUE)/7
conf_two4<-mean(as.numeric(m4$Q8.x), na.rm = TRUE)/7
conf_three4<-mean(as.numeric(m4$Q10), na.rm = TRUE)/7
conf_four4<-mean(as.numeric(m4$Q16), na.rm = TRUE)/7
conf_six4<-mean(as.numeric(m4$Q17), na.rm = TRUE)/7
conf_seven4<-mean(as.numeric(m4$Q6.x), na.rm = TRUE)/7
conf_eight4<-mean(as.numeric(m4$Q8.x), na.rm = TRUE)/7
##### Merge data together
pre_percentages4<-c(sum_one4,sum_two4,sum_three4,sum_four4,sum_six4,sum_seven4,sum_eight4)
pre_confidence4<-c(conf_one4,conf_two4,conf_three4,conf_four4,conf_six4,conf_seven4,conf_eight4)
data34<-as.data.frame(cbind(pre_percentages4,pre_confidence4))
# Transpose dataset 
data44<-t(data34)
data44<-`colnames<-`(data44, c("Sort","Sum","Avg","Median","IF THEN","Intercept","VLOOKUP"))
data44<-round(data44,2)
data44<-as.data.frame(data44)
x4 = c("Sort","Sum","Avg","Median","IF THEN","Intercept","VLOOKUP")
data44[1,]
Pre_4 = data44[1,]
Post_4 = round((data44[2,]),2)
#Post_ = round((data4[2,]/4),2)
library(reshape2)
library(stargazer)
to_plot4 <- data.frame(x=x4,y1=t(Pre_4),y2=t(Post_4))
melted4<-melt(to_plot4, id="x")

a<-ggplot(melted4,aes(x=x,y=value,fill=variable)) + 
  geom_bar(stat="identity",position = "dodge", alpha=.3) +labs(title = "Female Responses",y= "", x = "Question Topic")+ scale_fill_discrete(name = "Result", labels = c("Correct", "Confidence")) + theme(legend.position="top",legend.title = element_blank()) + scale_x_discrete(limits = level_order)+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) 

b<-ggplot(melted3,aes(x=x,y=value,fill=variable)) + 
  geom_bar(stat="identity",position = "dodge", alpha=.3) +labs(title = "Male Responses",y= "", x = "Question Topic")+ scale_fill_discrete(name = "Result", labels = c("Correct", "Confidence")) + theme(legend.position="top",legend.title = element_blank()) + scale_x_discrete(limits = level_order)+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

c<-ggplot(m, aes(x = Sex, y = question_percent, fill = Sex)) +
  geom_violin(alpha = 0.5) +
  geom_point(position = position_jitter(seed = 1, width = 0.05)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +  theme(legend.position = "none") +
  labs(title="Percent Correct by Gender ", x="Gender", y="Percent Correct") 

d<-ggplot(m, aes(x = Sex, y = ConfidenceAvg, fill = Sex)) +
  geom_violin(alpha = 0.5) +
  geom_point(position = position_jitter(seed = 1, width = 0.05)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +  theme(legend.position = "none") +
  labs(title="Average Confidence by Gender ", x="Gender", y="Average Confidence") 


e<-ggplot(m, aes(x = Ethnicity, y = question_percent, fill = Ethnicity)) +
 geom_violin(alpha = 0.5) +
  geom_point(position = position_jitter(seed = 1, width = 0.05)) +
 theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +  theme(legend.position = "none") +
 labs(title="Percent Correct by Ethnicity ", x="Ethnicity", y="Percent Correct")

f<-ggplot(m, aes(x = Ethnicity, y = ConfidenceAvg, fill = Ethnicity)) +
 geom_violin(alpha = 0.5) +
  geom_point(position = position_jitter(seed = 1, width = 0.05)) +
 theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +  theme(legend.position = "none") +
 labs(title="Confidence by Ethnicity ", x="Ethnicity", y="Average Confidence")

```

### Descriptive Statistics
###### Used log +1 to account for students with 0 percent
```{r,results='asis'}
stargazer(means, type="latex", title = "Descriptive Statistics of Variables")
```


```{r}
ggplot(melted,aes(x=x,y=value,fill=variable)) + 
  geom_bar(stat="identity",position = "dodge", alpha=.3) +labs(title = "Percent Correct and Degree of Confidence By Question",y= "", x = "Question Topic")+ scale_fill_discrete(name = "Result", labels = c("Correct", "Confidence")) + theme(legend.position="top",legend.title = element_blank()) + scale_x_discrete(limits = level_order) 

grid.arrange(a, b, ncol = 2,top = "Percent Correct and Degree of Confidence per Question By Gender") 
grid.arrange(c, d, ncol = 2, top="Violin of Gender Heterogeneity") 
grid.arrange(e, f, ncol = 2, top="Violin of Ethnicity Heterogeneity") 

```





Average confidence was rounded to the nearest whole number and then set as a factor to create dummies for each confidence level
```{r,results='asis'}
ols1<-lm(m$question_percentLog~m$Cumulative_GPA+m$Gender+m$Ethnicity_NRA_included+as.factor(m$Confidence))
stargazer(ols1,type="latex", title="Regression of Correct Percent Log on Covariates",covariate.labels = 
        c("Cumulative GPA", "Male", "Black", "Latino",
          "NRA", "Multiracial", "White", "Confidence 2","Confidence 3","Confidence 4","Intercept"),dep.var.labels = "Percent Correct Log")
```




